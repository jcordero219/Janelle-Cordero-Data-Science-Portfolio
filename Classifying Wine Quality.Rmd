---
title: "HW2-janelle-cordero"
author: "Janelle Cordero"
date: "January 28, 2019"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE,message=FALSE}
#install.packages("corrplot")
#install.packages("car")

knitr::opts_chunk$set(echo = TRUE,fig.align="center")
library(kableExtra)
library(psych)
library(MASS)
library(foreign)
library(class)
library(corrplot)
library(pROC)
library(scales)
library(car)

```

#Data and EDA

The following dataset includes 1,599 red wine samples that were evaluated through chemical tests (e.g. pH, acidity, etc.) and graded by wine experts based on sensory tests on a scale of 0 (very bad) to 10 (very excellent). To create a classification problem, I divided the expert rating into 2 categories wines with a grade from 0-5 were classified "poor quality" and wines with a grade of 6-10 were classified "high quality."


```{r wine}
wine <- read.table("winequality-red.csv",header=TRUE,sep=",")
kable(head(wine,10),caption="Wine Dataset") %>%
kable_styling(bootstrap_options = c("striped", "hover"))

#converting "quality" to binary
wine$quality_binary <- ifelse(wine$quality<=5,0,1)


```

Below are descriptive statistics regarding the wine dataset. There are 744 low quality wines and 855 high quality wines so the dataset is fairly balanced. Many variables seem to have a dense range of values centered around he median with many outliers.


```{r}

kable(describe(wine),caption="Descriptive Statistics") %>%
kable_styling(bootstrap_options = c("striped", "hover"))

boxplot(wine[-c(6,7)],main="Boxplots of Continuous Variables",col="slategray2",pch=20)
plot(as.factor(wine$quality_binary),main="Wine Quality",ylab="Frequency",col="slategray2")
```

Wine quality seems to have the highest correlation with **alcohol** and **volatile acidity**, so these variables may warrant more investigation and appear to be significant when modeling. Logistic Regression assumes that independent variables are not too highly correlated. The largest correlation in this dataset is $|0.68|$.

```{r}
#wine_cor <- round(cor(wine),2)
col <- colorRampPalette(c("indianred3","seashell1","darkseagreen"))(10)
corrplot(cor(wine),method="color",col=col)

```




```{r}
kable(round(cor(wine),2),caption="Correlation Matrix") %>%
kable_styling(bootstrap_options = c("striped", "hover"))

```


#Logistic Regression

I created a logistic regression model that would classify wine samples as low and high quality based on all descriptive predictors in the dataset. As expected, **alcohol** and **volatile.acidity** were very significant along with additional variables like **citric.acid**, **chlorides**, **free.sulfur.dioxide**, **total.sulfur,dioxide**, and **sulphates**. 


```{r Logistic Regression}

wine.log <- glm(quality_binary~.-quality,data=wine,family=binomial)
summary(wine.log)
```

The **fixed acidity** variable has a high VIF which indicated multicolinearity and must be dropped from further analysis to meet the logistic regression assumptions.

```{r}
kable(vif(wine.log),caption="VIF") %>%
kable_styling(bootstrap_options = c("striped", "hover"))


```



```{r Logistic Regression Change}

wine.log <- glm(quality_binary~.-quality-fixed.acidity-residual.sugar-density-pH-citric.acid,data=wine,family=binomial)
summary(wine.log)

```

The final model includes only significant variables and increases classification power. With only significant variables in the first model, **citric.acid** became insignificant and was removed. **alcohol** is the most significant variable and can be interpreted as follows:

+ A 1 unit increase in alcohol level in a wine sample results in a 0.87 increase in the log odds of the sample being a high quality wine.

##Predictions

Logistic regression predictions output the predicted probabilities that a wine sample is a high quality wine. The first 10 predictions and actuals are listed below. With a threshold of 0.5 (i.e. > 0.5 = high quality), this model correctly classified one instance and incorrectly classified 2 instances.

```{r Predictions}

wine.log.probs <- predict(wine.log,type="response")

first10preds <- cbind(wine.log.probs[1:10],wine$quality_binary[1:10])
names(first10preds) <- c("Predicted Pobability","Actual")

kable(first10preds,caption="Probability Predictions and Actuals") %>%
kable_styling(bootstrap_options = c("striped", "hover"))

#contrasts(quality_binary)  ##quality_binary is already binomial

wine.log.pred <- rep(0,nrow(wine))

#setting class labels
wine.log.pred[wine.log.probs>.5]=1

```


However, on the entire dataset, this model seems to do fairly well at classifying wine quality.

Accuracy = `r mean(wine.log.pred==wine$quality_binary)`

```{r}
#Confusion Matrix

kable(table(wine.log.pred,wine$quality_binary),caption="Confusion Matrix")%>%
kable_styling(bootstrap_options = c("striped", "hover"))


```


#Train/Test Split

However, the accuracy is not the most accurate metric for this model. The model is fit on the entire dataset and therefore has not been tested on unseen data. To validate accuracy and prevent overfitting, I split the data into a test and train set. The model will be fit on the train set and the test set will be used to determine accuracy. I used a random sample of 20% of my data to test which resulted in 319 instances.

```{r}
set.seed(100)
train_ind <- sample(seq_len(nrow(wine)),size=(0.2*nrow(wine)))

test <- wine[train_ind,]
train <- wine[-train_ind,]


kable(head(train),caption="Train Set")%>%
kable_styling(bootstrap_options = c("striped", "hover"))
#nrow(train)

kable(head(test),caption="Test Set")%>%
kable_styling(bootstrap_options = c("striped", "hover"))
#nrow(test)


```

#Logistic Regression on Train Set

I created a logistic regression on the train set with all predictor variables and now I have a different set of significant variables.

```{r Logistic Regression on train set}
wine.log2 <- glm(quality_binary~.-quality,data=train,family=binomial)
summary(wine.log2)

```

I narrowed the model down to include only significant variables. Citric acid became insignificant again and was removed.

```{r Logistic Regression on train set2}
wine.log2 <- glm(quality_binary~.-quality-fixed.acidity-residual.sugar-chlorides-density-pH-citric.acid,data=train,family=binomial)
summary(wine.log2)

```



```{r Test set prediction}

wine.log2.probs <- predict(wine.log2,test,type="response")


wine.log2.pred <- rep(0,nrow(test))

#setting class labels
wine.log2.pred[wine.log2.probs>.5]=1


#confusion matrix
#accuracy

kable(table(wine.log2.pred,test$quality_binary),caption="Confusion Matrix")%>%
kable_styling(bootstrap_options = c("striped", "hover"))


```

Now the true accuracy of the model is revealed as `r mean(wine.log2.pred==1)`. This means our model is a bit better than a 50/50 guess.

The following plot is the ROC curve for the final logistic regression model.


```{r}
plot(roc(test$quality_binary,wine.log2.pred),main="ROC Curve",col="darkblue")

```



#Linear Discriminat Analysis

Next, I used a Linear Discriminant Analysis (LDA) model to try to classify wine quality. I will continue to use the same variables in the train set while testing on the test set to find the true accuracy of the model. 



```{r}

wine.lda = lda(quality_binary~.-quality-fixed.acidity-residual.sugar-chlorides-density-pH-citric.acid,data=train)
wine.lda

```

The LDA output first displays the % share of low and high quality wines in the train dataset. There are `r percent(wine.lda$prior[1])` high quality wines in the dataset. The group means are the means of the variable within each class. The coefficients determines the line that separates the data into low and high quality wines. the equations is as follows:

`r wine.lda$scaling[1]`$*$**volatile.acidity** $+$ `r wine.lda$scaling[2]`$*$**free.sulfue.dioxide** $+$ `r wine.lda$scaling[3]`$*$**total.sulfur.dioxide** $+$ `r wine.lda$scaling[4]`$*$**sulphates** $+$ `r wine.lda$scaling[5]`$*$**alcohol**

The Plots of linear discriminants display a clear difference between the two wine quality classes. Low quality wines are centered around -1 whereas high quality wines are centered around 1.

```{r}
plot(wine.lda,col="slategray2")

#LDA Predictions
wine.lda.pred <- predict(wine.lda,test)

```


The confusion matrix below displays the predicted classes vs. the actuals on the test set. The LDA model had an accuracy of `r mean(wine.lda.pred$class==test$quality_binary)` on the test data. This is a dramatic improvement on the logistic regression model.

```{r}

#confusion matrix
kable(table(wine.lda.pred$class,test$quality_binary),caption="Confusion Matrix")%>%
kable_styling(bootstrap_options = c("striped", "hover"))



sum(wine.lda.pred$posterior[,1]>=.5)
sum(wine.lda.pred$posterior[,1]<.5)


```




#Quadratic  Discriminant Analysis with all variables

The quadratic discriminant analysis model is similar to the linear discriminant analysis model, except it does not assume that the predictor variables are linearly related to the response variables.


```{r}
wine.qda <- qda(quality_binary~.-quality,data=train)
wine.qda
```

The following confusion matrix displays the predictions of the QDA model vs. the actual values in the test set.

```{r}
wine.qda.class <- predict(wine.qda,test)$class
kable(table(wine.qda.class,test$quality_binary),caption="Confusion Matrix")%>%
kable_styling(bootstrap_options = c("striped", "hover"))

```


The accuracy of the QDA model turns out to be `r mean(wine.qda.class==test$quality_binary)` which is similar to the LDA model but does not perform as well.


#K-Nearest Neighbors

The K Nearest Neighbors model classifies instances based on a majority vote of instances that are similar. For the kNN model, I will continue to use the train and test set as well as the final set of predictor variables derived from the logistic regression model.

The following kNN model takes in only the predictor variables in the train set and test set separately.


```{r}
x_vars_train <- train[,c("alcohol","free.sulfur.dioxide","sulphates","total.sulfur.dioxide","volatile.acidity")]
kable(head(x_vars_train),caption="Predictor Variables in Train Set")%>%
kable_styling(bootstrap_options = c("striped", "hover"))

x_vars_test <- test[,c("alcohol","free.sulfur.dioxide","sulphates","total.sulfur.dioxide","volatile.acidity")]
kable(head(x_vars_test),caption="Predictor Variables in Test Set")%>%
kable_styling(bootstrap_options = c("striped", "hover"))

set.seed(1)
wine.knn.pred <- knn(x_vars_train,x_vars_test,train$quality_binary,k=1)

```

The following confusion matrix displays displays the predictions of the kNN model when k=1 vs. the actual values in the test set. The model results in an accuracy of `r mean(wine.knn.pred==test$quality_binary)`.

```{r}


#Confusion Matrix
kable(table(wine.knn.pred,test$quality_binary))%>%
kable_styling(bootstrap_options = c("striped", "hover"))


```

To test for the best value of k, I plotted k against accuracy for k=1:100. k=1 results in the best accuracy.

```{r}

knn_x <- vector()
knn_y <- vector()

for(i in 1:100){
  wine.knn.pred <- knn(x_vars_train,x_vars_test,train$quality_binary,k=i)
  mean(wine.knn.pred==test$quality_binary)
  knn_x[i] <- i
  knn_y[i] <- mean(wine.knn.pred==test$quality_binary)
}
  
plot(knn_x,knn_y,main="kNN Accuracy",ylab="Accuracy",xlab="k",col="mediumorchid",type="l")

```